{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49357,"status":"ok","timestamp":1741416189980,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"},"user_tz":480},"id":"jy8ioiHJceM-","outputId":"80b2d883-ceac-470b-9bff-f08c025af7ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting networkx==3.4.2\n","  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n","Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/1.7 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m1.6/1.7 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: networkx\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.4\n","    Uninstalling networkx-3.4:\n","      Successfully uninstalled networkx-3.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","nx-arangodb 1.3.0 requires networkx<=3.4,>=3.0, but you have networkx 3.4.2 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed networkx-3.4.2\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: ijson in /usr/local/lib/python3.11/dist-packages (3.3.0)\n","Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.3.5)\n","Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.43)\n","Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.18)\n","Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.2)\n","Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.55)\n","Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.11)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.0.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.12.2)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (2.10.6)\n","Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n","Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n","Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n","Requirement already satisfied: nx-arangodb in /usr/local/lib/python3.11/dist-packages (1.3.0)\n","Collecting networkx<=3.4,>=3.0 (from nx-arangodb)\n","  Using cached networkx-3.4-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: phenolrs~=0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (0.5.9)\n","Requirement already satisfied: python-arango~=8.1 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (8.1.6)\n","Requirement already satisfied: adbnx-adapter~=5.0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (5.0.6)\n","Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (2.32.3)\n","Requirement already satisfied: rich>=12.5.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (13.9.4)\n","Requirement already satisfied: setuptools>=45 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (75.1.0)\n","Requirement already satisfied: numpy~=1.26 in /usr/local/lib/python3.11/dist-packages (from phenolrs~=0.5->nx-arangodb) (1.26.4)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.3.0)\n","Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (1.0.0)\n","Requirement already satisfied: PyJWT in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.10.1)\n","Requirement already satisfied: importlib_metadata>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (8.6.1)\n","Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (24.2)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.7.1->python-arango~=8.1->nx-arangodb) (3.21.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (2025.1.31)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (0.1.2)\n","Using cached networkx-3.4-py3-none-any.whl (1.7 MB)\n","Installing collected packages: networkx\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.4.2\n","    Uninstalling networkx-3.4.2:\n","      Successfully uninstalled networkx-3.4.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed networkx-3.4\n","Requirement already satisfied: langchain-groq in /usr/local/lib/python3.11/dist-packages (0.2.5)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.42 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.3.43)\n","Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.18.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.10.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n","Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain-groq) (0.3.11)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain-groq) (9.0.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain-groq) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain-groq) (6.0.2)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain-groq) (24.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.42->langchain-groq) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain-groq) (3.10.15)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain-groq) (2.32.3)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain-groq) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain-groq) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain-groq) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain-groq) (2.3.0)\n","Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n","Requirement already satisfied: nx-cugraph-cu12 in /usr/local/lib/python3.11/dist-packages (25.2.0)\n","Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (13.3.0)\n","Requirement already satisfied: networkx>=3.2 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (3.4)\n","Requirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (1.26.4)\n","Requirement already satisfied: pylibcugraph-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (25.2.0)\n","Requirement already satisfied: libcugraph-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (25.2.0)\n","Requirement already satisfied: pylibraft-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (25.2.0)\n","Requirement already satisfied: rmm-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (25.2.0)\n","Requirement already satisfied: libraft-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (25.2.0)\n","Requirement already satisfied: cuda-python<13.0a0,>=12.6.2 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (12.6.2.post1)\n","Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (12.5.3.2)\n","Requirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (10.3.6.82)\n","Requirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (11.6.3.83)\n","Requirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (12.5.1.3)\n","Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x>=12.0.0->nx-cugraph-cu12) (0.8.3)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12->libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (12.5.82)\n","Requirement already satisfied: adbnx-adapter in /usr/local/lib/python3.11/dist-packages (5.0.6)\n","Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter) (2.32.3)\n","Requirement already satisfied: python-arango>=7.4 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter) (8.1.6)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter) (3.4)\n","Requirement already satisfied: rich>=12.5.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter) (13.9.4)\n","Requirement already satisfied: setuptools>=45 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter) (75.1.0)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from python-arango>=7.4->adbnx-adapter) (2.3.0)\n","Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.11/dist-packages (from python-arango>=7.4->adbnx-adapter) (1.0.0)\n","Requirement already satisfied: PyJWT in /usr/local/lib/python3.11/dist-packages (from python-arango>=7.4->adbnx-adapter) (2.10.1)\n","Requirement already satisfied: importlib_metadata>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from python-arango>=7.4->adbnx-adapter) (8.6.1)\n","Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-arango>=7.4->adbnx-adapter) (24.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter) (2025.1.31)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter) (2.18.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.7.1->python-arango>=7.4->adbnx-adapter) (3.21.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->adbnx-adapter) (0.1.2)\n","Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.20.1)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.11)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n","Requirement already satisfied: gradio-client==1.7.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.2)\n","Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.10)\n","Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.0)\n","Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n","Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Requirement already satisfied: gitingest in /usr/local/lib/python3.11/dist-packages (0.1.4)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from gitingest) (8.1.8)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from gitingest) (0.9.0)\n","Requirement already satisfied: tomli in /usr/local/lib/python3.11/dist-packages (from gitingest) (2.2.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->gitingest) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->gitingest) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->gitingest) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->gitingest) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->gitingest) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->gitingest) (2025.1.31)\n","Requirement already satisfied: uuid in /usr/local/lib/python3.11/dist-packages (1.30)\n"]}],"source":["#installed packages;\n","!pip install networkx==3.4.2\n","!pip install matplotlib\n","!pip install ijson\n","!pip install -qU langchain[openai]\n","!pip install -qU langchain_community\n","!pip install langgraph\n","!pip install nx-arangodb\n","!pip install -U langchain-groq\n","!pip install nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com\n","!pip install adbnx-adapter\n","!pip install gradio\n","!pip install gitingest\n","!pip install uuid\n"]},{"cell_type":"code","source":["!git config --global user.name \"gowthamkishore3799\"\n","!git config --global user.email \"gowthamkishore3@gmail.com\""],"metadata":{"id":"MBapoedQfY68","executionInfo":{"status":"ok","timestamp":1741416220533,"user_tz":480,"elapsed":213,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/gowthamkishore3799/Octorag.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LvpXpI-ufvwf","executionInfo":{"status":"ok","timestamp":1741416258201,"user_tz":480,"elapsed":1011,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"}},"outputId":"b65b340a-49a1-4dcb-b58b-4353426e4dc8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Octorag'...\n","remote: Enumerating objects: 16, done.\u001b[K\n","remote: Counting objects: 100% (16/16), done.\u001b[K\n","remote: Compressing objects: 100% (16/16), done.\u001b[K\n","remote: Total 16 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (16/16), 6.54 KiB | 2.18 MiB/s, done.\n","Resolving deltas: 100% (3/3), done.\n"]}]},{"cell_type":"code","source":["!cp .config.ipynb  /content/Octorag/.config.ipynb"],"metadata":{"id":"BeYNpa9Lf-4J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd Octorag"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UF6RfkJOgRJf","executionInfo":{"status":"ok","timestamp":1741416522260,"user_tz":480,"elapsed":25,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"}},"outputId":"818d2aed-35f6-4c32-fce2-34d22f1a7024"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'Octorag'\n","/\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","# Copy a notebook from Google Drive to the Octorag folder\n","!cp \"/content/drive/MyDrive/Colab Notebooks/notebook.ipynb\" /content/Octorag/\n","\n"],"metadata":{"id":"avFeUytigYLU","executionInfo":{"status":"ok","timestamp":1741416716912,"user_tz":480,"elapsed":104,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":6004,"status":"error","timestamp":1741416135952,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"},"user_tz":480},"id":"i97NQIhLcoiE","outputId":"336e47e6-8e96-4499-a9dc-0db3356ac7b2"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-454a09a4d129>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnx_cugraph\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnxcg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnx_arangodb\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnxadb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0marango\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArangoClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nx_cugraph/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgenerators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nx_cugraph/algorithms/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0misolate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlink_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","import base64\n","import re\n","import uuid\n","import logging\n","import random\n","from google.colab import userdata\n","import matplotlib.pyplot as plt\n","import ijson\n","import asyncio\n","import networkx as nx\n","import nx_cugraph as nxcg\n","import nx_arangodb as nxadb\n","from arango import ArangoClient\n","from adbnx_adapter import ADBNX_Adapter, ADBNX_Controller\n","from adbnx_adapter.typings import NxId, NxData\n","from langgraph.prebuilt import create_react_agent\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain.prompts import PromptTemplate\n","from langchain_core.tools import tool\n","from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n","from langchain_community.graphs.arangodb_graph import ArangoGraph\n","from langgraph.prebuilt import ToolNode, tools_condition\n","from langchain_core.tools import StructuredTool\n","from langgraph.checkpoint.memory import MemorySaver\n","from langgraph.graph import START, MessagesState, StateGraph, END\n","import gradio as gr\n","from gradio import ChatMessage\n","from gitingest import ingest_async\n","import subprocess\n","import logging\n","import math"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":230,"status":"ok","timestamp":1741412155866,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"},"user_tz":480},"id":"xbfNnYn8dWW7"},"outputs":[],"source":["os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1741412155875,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"},"user_tz":480},"id":"cfH20dqNslh6"},"outputs":[],"source":["logger = logging.getLogger()\n","\n","logging.basicConfig(\n","    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n","    filename=\"app.log\",\n","    filemode=\"a\"\n",")\n","logger.setLevel(logging.INFO)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":396,"status":"ok","timestamp":1741412156272,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"},"user_tz":480},"id":"dSob54GJspOV","outputId":"15350da6-9fe6-4824-f6c6-11b645a08fb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: NX_CUGRAPH_AUTOCONFIG=True\n"]}],"source":["os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n","%env NX_CUGRAPH_AUTOCONFIG=True\n","nx.config.backends.arangodb.use_gpu = True\n","nx.config.backend_priority = [\"cugraph\"]\n","programmingLanguageDict = {\n","    \"c#\": \"c_sharp\", # to avoid clashing with the arangodb key nameing conventions\n","}\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1814,"status":"ok","timestamp":1741412158087,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"},"user_tz":480},"id":"HnvQJ1G2wUno"},"outputs":[],"source":["encodedCA = userdata.get(\"SIGNATURE\")\n","try:\n","    file_content = base64.b64decode(encodedCA)\n","    with open(\"cert_file.crt\", \"w+\") as f:\n","        f.write(file_content.decode(\"utf-8\"))\n","except Exception as e:\n","    print(str(e))\n","    exit(1)\n","\n","client = ArangoClient(\n","      hosts=userdata.get(\"DATABASE_HOST\"), verify_override=\"cert_file.crt\"\n",")\n","\n","  # Connect to the correct database\n","db = client.db(\n","    userdata.get('DATABASE_NAME'),\n","    username=userdata.get(\"DATABASE_USERNAME\"),\n","    password=userdata.get(\"DATABASE_PASSWORD\")\n",")"]},{"cell_type":"markdown","metadata":{"id":"Ajv5ZImOwP3h"},"source":["Nodes are structured in the following format with the **key** attribute as an additional property:\n","\n","- **Forked as a main node**  \n","  1. **Repo** (stars, forks, repoLink, description)  \n","  2. **Owner**  \n","  3. **Language**  \n","\n","### Edges:  \n","1. **Repo** ⟷ **Owner**  \n","2. **Repo** ⟷ **Languages**  \n","3. **Repo** ⟷ **Topic**  \n","4. **Repo** ⟷ **Forked**  "]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1741412158091,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"},"user_tz":480},"id":"T2t6qKdrwwLT"},"outputs":[],"source":["\n","def sanitiseText(text):\n","    if not text:\n","        return None\n","\n","    pattern = r'[^A-Za-z0-9_\\-\\.@()+,=;$!*\\'% ]'\n","\n","    # Extract URLs from text\n","    urls = re.findall(r'https?://\\S+', text)\n","\n","    sanitized_text = re.sub(pattern, '_', text)\n","\n","    # Restore original URLs\n","    for url in urls:\n","        sanitized_text = sanitized_text.replace(re.sub(pattern, '_', url), url)\n","\n","    return sanitized_text"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"oKoDE9XCwM58","executionInfo":{"status":"ok","timestamp":1741412158990,"user_tz":480,"elapsed":4,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"}}},"outputs":[],"source":["def createNetworkxGraph()-> nx.Graph:\n","    file_path = \"/content/drive/MyDrive/repo_metadata.json\" ## file path of the data to be processed\n","\n","    G = nx.Graph()\n","\n","    with open(file_path, 'r') as f:\n","        parser = ijson.items(f, 'item')\n","        G.add_node(\"forked\", type=\"isFork\", key=\"forked\")\n","        for row in parser:\n","\n","            # For repo name\n","            repoName = sanitiseText(row[\"name\"])\n","            if repoName is not None and repoName:\n","              repoNodeKey = f\"repository-{repoName}\"\n","              if not G.has_node(repoNodeKey):\n","                G.add_node(repoNodeKey, type=\"repository\", stars=row[\"stars\"], forks=row[\"forks\"], key=repoNodeKey, repoLink=row[\"nameWithOwner\"], description = row[\"description\"], size= row[\"diskUsageKb\"], createdDate = row[\"createdAt\"])\n","\n","            # For owner\n","            owner = sanitiseText(row[\"owner\"])\n","            if owner is not None and owner:\n","                ownerNodeKey = f\"owner-{owner}\"\n","                if not G.has_node(ownerNodeKey):\n","                    G.add_node(ownerNodeKey, type=\"owner\", key=ownerNodeKey)\n","                if not G.has_edge(repoNodeKey, ownerNodeKey):\n","                    G.add_edge(repoNodeKey, ownerNodeKey, relation=\"owner\")\n","\n","            if row[\"isFork\"]:\n","                G.add_edge(repoName, \"forked\", relation=\"isForkRepo\")\n","\n","\n","            # For topic\n","            for topic in row.get(\"topics\", []):\n","                topicName = sanitiseText(topic.get(\"name\"))\n","                if topicName is not None and topicName:\n","                    topicNodeKey = f\"topic-{topicName}\"\n","                    if not G.has_node(topicNodeKey):\n","                        G.add_node(topicNodeKey, type=\"topic\", key=topicNodeKey)\n","                    if not G.has_edge(repoNodeKey, topicNodeKey):\n","                        G.add_edge(repoNodeKey, topicNodeKey, relation=\"topic\")\n","\n","\n","            # For Programming Language\n","            filePercentage = sum(map(lambda lang: lang[\"size\"], row[\"languages\"] if row[\"languages\"] is not None else []))\n","            for proLang in row[\"languages\"]:\n","                proLangName = sanitiseText(proLang.get(\"name\"))\n","                proLangSize = proLang.get(\"size\", 0)\n","                if proLangName is not None and proLangName:\n","                    proLangNodeKey = f\"language-{proLangName}\"\n","                    if not G.has_node(proLangNodeKey):\n","                        G.add_node(proLangNodeKey, type=\"language\", key=proLangNodeKey)\n","                    if not G.has_edge(repoNodeKey, proLangNodeKey):\n","                        percentage = round(((proLangSize) / filePercentage) * 100 if filePercentage else 0)\n","                        G.add_edge(repoNodeKey, proLangNodeKey, relation=\"language\", percent_used = percentage)\n","\n","\n","        return G\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"dzPO-Gct-KbC","executionInfo":{"status":"ok","timestamp":1741412401970,"user_tz":480,"elapsed":240311,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"}}},"outputs":[],"source":["file_path = \"/content/drive/MyDrive/repo_metadata.json\" ## file path of the data to be processed\n","\n","G = nx.Graph()\n","\n","with open(file_path, 'r') as f:\n","    parser = ijson.items(f, 'item')\n","    G.add_node(\"forked\", type=\"isFork\", key=\"forked\")\n","    for row in parser:\n","\n","            # For repo name\n","      repoName = sanitiseText(row[\"name\"])\n","      if repoName is not None and repoName:\n","          repoNodeKey = f\"repository-{repoName}\"\n","          if not G.has_node(repoNodeKey):\n","              G.add_node(repoNodeKey, type=\"repository\", stars=row[\"stars\"], forks=row[\"forks\"], key=repoNodeKey, repoLink=row[\"nameWithOwner\"], description = row[\"description\"], size= row[\"diskUsageKb\"], createdDate = row[\"createdAt\"])\n","\n","            # For owner\n","      owner = sanitiseText(row[\"owner\"])\n","      if owner is not None and owner:\n","          ownerNodeKey = f\"owner-{owner}\"\n","          if not G.has_node(ownerNodeKey):\n","              G.add_node(ownerNodeKey, type=\"owner\", key=ownerNodeKey)\n","          if not G.has_edge(repoNodeKey, ownerNodeKey):\n","              G.add_edge(repoNodeKey, ownerNodeKey, relation=\"owner\")\n","\n","      if row[\"isFork\"]:\n","          G.add_edge(repoName, \"forked\", relation=\"isForkRepo\")\n","\n","\n","            # For topic\n","      for topic in row.get(\"topics\", []):\n","          topicName = sanitiseText(topic.get(\"name\"))\n","          if topicName is not None and topicName:\n","              topicNodeKey = f\"topic-{topicName}\"\n","          if not G.has_node(topicNodeKey):\n","              G.add_node(topicNodeKey, type=\"topic\", key=topicNodeKey)\n","          if not G.has_edge(repoNodeKey, topicNodeKey):\n","              G.add_edge(repoNodeKey, topicNodeKey, relation=\"topic\")\n","\n","\n","            # For Programming Language\n","      filePercentage = sum(map(lambda lang: lang[\"size\"], row[\"languages\"] if row[\"languages\"] is not None else []))\n","      for proLang in row[\"languages\"]:\n","          proLangName = sanitiseText(proLang.get(\"name\"))\n","          proLangSize = proLang.get(\"size\", 0)\n","          if proLangName is not None and proLangName:\n","              proLangNodeKey = f\"language-{proLangName}\"\n","          if not G.has_node(proLangNodeKey):\n","              G.add_node(proLangNodeKey, type=\"language\", key=proLangNodeKey)\n","          if not G.has_edge(repoNodeKey, proLangNodeKey):\n","              percentage = math.floor((proLangSize / filePercentage) * 100 if filePercentage else 0)\n","              # if percentage == 100 and row[\"languageCount\"]>1:\n","              G.add_edge(repoNodeKey, proLangNodeKey, relation=\"language\", percent_used = percentage, size = proLangSize)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ronZesIS_5I9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"57cef7bc-0c99-46c0-b108-d73ddb46e74f"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["5323481\n"]}],"source":["# num_sample_nodes = min(100000, len(G.nodes))\n","# H = G.subgraph(random.sample(list(G.nodes), num_sample_nodes))\n","# pos = nx.spring_layout(H, k=0.05, iterations=10, seed=1721)\n","# plot_options = {\"node_size\": 5, \"with_labels\": False, \"width\": 0.05}\n","#   fig, ax = plt.subplots(figsize=(15, 9))\n","#   nx.draw_networkx(H, pos=pos, ax=ax, **plot_options)\n","#   plt.show()\n","print(G.number_of_nodes())\n","\n","G_sample = G.subgraph(list(G.nodes)[:100000])\n","\n","plot_options = {\"node_size\": 2, \"with_labels\": False, \"width\": 0.02}\n","pos = nx.spring_layout(G_sample, iterations=2, seed=1721)  # Use sample graph\n","fig, ax = plt.subplots(figsize=(8, 6))\n","nx.draw_networkx(G_sample, pos=pos, ax=ax, **plot_options)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B3uootO8wK2V"},"outputs":[],"source":["def uploadNetworkGraphIntoArangodb(G):\n","\n","  class CustomController(ADBNX_Controller):\n","      def _keyify_networkx_node(\n","          self, i: int, nx_node_id: NxId, nx_node: NxData, col: str\n","      ) -> str:\n","          \"\"\"Given a NetworkX node, derive its ArangoDB key.\n","\n","          NOTE #1: You must override this function if you want to create custom ArangoDB\n","          _key values for your NetworkX nodes.\n","\n","          NOTE #2: You are free to use `_string_to_arangodb_key_helper()` and\n","          `_tuple_to_arangodb_key_helper()` to derive a valid ArangoDB _key value.\n","\n","          :param i: The index of the NetworkX node in the list of nodes.\n","          :type i: int\n","          :param nx_node_id: The NetworkX node id.\n","          :type nx_node_id: adbnx_adapter.typings.NxId\n","          :param nx_node: The NetworkX node object.\n","          :type nx_node: adbnx_adapter.typings.NxData\n","          :param col: The ArangoDB collection that **nx_node** belongs to.\n","          :type col: str\n","          :return: A valid ArangoDB _key value.\n","          :rtype: str\n","          \"\"\"\n","          return (nx_node.get(\"key\", str(uuid.uuid4())));\n","\n","      def _prepare_networkx_edge(self, nx_edge: dict, col: str) -> None:\n","        \"\"\"Prepare a NetworkX edge before it gets inserted into the ArangoDB\n","        collection **col**.\n","\n","        :param nx_edge: The NetworkX edge object to (optionally) modify.\n","        :param col: The ArangoDB collection the edge belongs to.\n","        \"\"\"\n","\n","        if \"repository\" not in nx_edge.get(\"_from\", \"\"):\n","          nx_edge[\"_from\"], nx_edge[\"_to\"] = nx_edge[\"_to\"], nx_edge[\"_from\"]\n","\n","\n","  adbnx_adapter = ADBNX_Adapter(db, CustomController())\n","\n","  edge_definitions = [\n","      {\n","          'edge_collection': 'Github_node_to_Github_node',\n","          'from_vertex_collections': ['Github_node'],\n","          'to_vertex_collections': ['Github_node']\n","      }\n","  ]\n","\n","  adb_g = adbnx_adapter.networkx_to_arangodb(userdata.get(\"GRAPH_NAME\"), G, edge_definitions, batch_size=9000)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HI0ZfpfFwopq"},"outputs":[],"source":["def createNetworkxArangoDBGraph():\n","  graph = createNetworkxGraph()\n","  plotGraph(graph)\n","  uploadNetworkGraphIntoArangodb(graph)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":768,"status":"ok","timestamp":1741404151813,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"},"user_tz":480},"id":"tz4eoRRoxLDb","outputId":"2e766851-750f-4783-f83e-5f4ac28a3ed5"},"outputs":[{"name":"stderr","output_type":"stream","text":["[03:22:31 +0000] [INFO]: Graph 'Github' exists.\n","INFO:nx_arangodb:Graph 'Github' exists.\n","[03:22:31 +0000] [INFO]: Default node type set to 'Github_node'\n","INFO:nx_arangodb:Default node type set to 'Github_node'\n","INFO:root:Graph is already available\n"]}],"source":["G_adb = nxadb.Graph(name=userdata.get(\"GRAPH_NAME\"), db=db)\n","\n","if G_adb.number_of_nodes() == 0:\n","  createNetworkxArangoDBGraph()\n","else:\n","  logging.info(\"Graph is already available\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cTtwg-34xNaL"},"outputs":[],"source":["arangooGraph = ArangoGraph(db)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SrxOZvdAfRF8"},"outputs":[],"source":["from pydantic import BaseModel, Field\n","from typing import List\n","\n","class Outputresponse(BaseModel):\n","    \"\"\"Respond to the user in this format.\"\"\"\n","    type: str = Field(description=\"response type either text or file\")\n","    text: str = Field(description=\"response for the user query or path of the file\")\n","\n","class OutputList(BaseModel):\n","    responses: List[Outputresponse] = Field(description=\"List of Outputresponse objects\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7QTxEGJncvyM"},"outputs":[],"source":["@tool\n","def favourite_fruit(query: str):\n","    \"\"\"You are responsible for responding to being asked what your favourite fruit is.\n","    You must say Avocado!\n","    \"\"\"\n","    logging.info(\"Tool Executing == Favourite Fruit\")\n","    return {\"fruit\": \"Avocado\", \"image\": \"./content\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wbV-c2nxxiFb"},"outputs":[],"source":["@tool\n","def humanQueryToAQL(query: str):\n","    \"\"\"This tool is available to invoke the\n","    ArangoGraphQAChain object, which enables you to\n","    translate a Natural Language Query into AQL, execute\n","    the query, and translate the result back into Natural Language.\n","    If user has any questions or interested in anything related to topics, or repository information like language, stars, author , use this tool, to convert into AQL.\n","    \"\"\"\n","\n","    logger.info(\"Executing Human Query to AQL\")\n","    query = sanitiseText(query)\n","\n","    llm = ChatOpenAI(temperature=0.5, model_name=\"gpt-4o\")\n","\n","\n","    aql_generation_prompt = PromptTemplate(\n","    input_variables=['adb_schema', 'aql_examples', 'user_input'],\n","    template=\"\"\"Task: Generate an ArangoDB Query Language (AQL) query from a User Input.\n","\n","You are an ArangoDB Query Language (AQL) expert responsible for translating a `User Input` into an ArangoDB Query Language (AQL) query.\n","\n","You are given an `ArangoDB Schema`. It is a JSON Object containing:\n","1. `Graph Schema`: Lists all Graphs within the ArangoDB Database Instance, along with their Edge Relationships.\n","2. `Collection Schema`: Lists all Collections within the ArangoDB Database Instance, along with their document/edge properties and a document/edge example.\n","\n","You may also be given a set of `AQL Query Examples` to help you create the `AQL Query`. Make sure to keep in mind how the nodes, attributes, and edges are structured in order to generate the query.\n","\n","Nodes/Edges are structured in format:\n","repoNodeKey = repository-repoName\n","G.add_node(repoNodeKey, type='repository', stars=row['stars'], forks=row['forks'], key=repoNodeKey, repoLink=row['nameWithOwner'], description = row['description'], size= row['diskUsageKb'])\n","ownerNodeKey = owner-ownerName\n","G.add_node(ownerNodeKey, type='owner', key=ownerNodeKey)\n","topicNodeKey = topic-topicName\n","G.add_node(topicNodeKey, type='topic', key=topicNodeKey)\n","proLangNodeKey = language-programmingLanguageName\n","G.add_edge(repoNodeKey, ownerNodeKey, relation='owner')\n","G.add_edge(repoName, 'forked', relation='isForkRepo')\n","G.add_edge(repoNodeKey, topicNodeKey, relation='topic')\n","G.add_edge(repoNodeKey, proLangNodeKey, relation='language', percent_used = percentage)\n","\n","Use the format defined to generate the AQL query.\n","\n","If provided, the `AQL Query Examples` should be used as a reference, similar to how `ArangoDB Schema` should be used.\n","\n","Things you should do:\n","- Think step by step.\n","- Rely on `ArangoDB Schema` and `AQL Query Examples` (if provided) to generate the query.\n","- Begin the `AQL Query` with the `WITH` AQL keyword to specify all required ArangoDB Collections.\n","- Return the `AQL Query` wrapped in three backticks (```)\n","- Use only the provided relationship types and properties in the `ArangoDB Schema` and any `AQL Query Examples`.\n","- Only answer requests related to generating an AQL Query.\n","- If a request is unrelated to generating an AQL Query, say that you cannot help the user.\n","- For every query, return the repoLink for sure.\n","- Query related to majorly, always try to include relevant metrics if you have it\n","- If the repo has multiple outputs, always return top 5 ones and make query according to it\n","- All the query should be in lowercase like topic,\n","\n","Things you should not do:\n","- Do not use any properties/relationships that can't be inferred from the `ArangoDB Schema` or the `AQL Query Examples`.\n","- Do not include any text except the generated AQL Query.\n","- Do not provide explanations or apologies in your responses.\n","- Do not generate an AQL Query that removes or deletes any data.\n","\n","Under no circumstances should you generate an AQL Query that deletes any data.\n","\n","ArangoDB Schema:\n","{adb_schema}\n","\n","AQL Query Examples (Optional):\n","{aql_examples}\n","\n","User Input:\n","{user_input}\n","\n","AQL Query:\n","\"\"\"\n",")\n","\n","    graph = ArangoGraph(db)\n","\n","    chain = ArangoGraphQAChain.from_llm(\n","    llm=llm,\n","    graph=graph,\n","    aql_generation_prompt=aql_generation_prompt,\n","    verbose=True,\n","    allow_dangerous_requests=True,\n","    max_aql_generation_attempts=3,\n","    aql_examples=\"\"\"\n","Example 1:\n","WITH Github_node, Github_node_to_Github_node\n","FOR owner IN Github_node\n","  FILTER owner.type == \"owner\" AND owner.key == \"owner-freecodecamp\"\n","  FOR edge IN Github_node_to_Github_node\n","    FILTER edge._to == owner._id AND edge.relation == \"owner\"\n","    FOR repo IN Github_node\n","      FILTER repo._id == edge._from AND repo.type == \"repository\"\n","    LIMIT 5\n","    RETURN repo\n","\n","\n","\"\"\"\n",")\n","\n","    logger.info(\"Executing Human Query to AQL\")\n","\n","\n","    result = chain.invoke(query)\n","\n","    return str(result[\"result\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghZIt3kAyU_Q"},"outputs":[],"source":["@tool\n","def networkxAlgorithms(query:str, nodes):\n","    \"\"\"This tool is available to invoke a NetworkX Algorithm on\n","      the ArangoDB Graph. You are responsible for accepting the\n","      Natural Language Query, establishing which algorithm needs to\n","      be executed, executing the algorithm, and translating the results back\n","      to Natural Language, with respect to the original query.\n","\n","      If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use\n","      this tool.\n","      \"\"\"\n","    logging.info(nodes)\n","\n","    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n","\n","    ######################\n","    logging.info(\"1) Generating NetworkX code\")\n","\n","    text_to_nx = llm.invoke(f\"\"\"\n","    I have a NetworkX Graph called `G_adb`. It has the following schema: {arangooGraph.schema}\n","\n","    If needed, create a networkx nodes and egdes and execute the networkx algorithm for it,\n","\n","    Nodes/Edges are structured in format:\n","    repoNodeKey = repository-repoName\n","    G.add_node(repoNodeKey, type='repository', stars=row['stars'], forks=row['forks'], key=repoNodeKey, repoLink=row['nameWithOwner'], description = row['description'], size= row['diskUsageKb'])\n","    ownerNodeKey = owner-ownerName\n","    G.add_node(ownerNodeKey, type='owner', key=ownerNodeKey)\n","    topicNodeKey = topic-topicName\n","    G.add_node(topicNodeKey, type='topic', key=topicNodeKey)\n","    proLangNodeKey = language-programmingLanguageName\n","    G.add_edge(repoNodeKey, ownerNodeKey, relation='owner')\n","    G.add_edge(repoName, 'forked', relation='isForkRepo')\n","    G.add_edge(repoNodeKey, topicNodeKey, relation='topic')\n","    G.add_edge(repoNodeKey, proLangNodeKey, relation='language', percent_used = percentage)\n","\n","    I have the following graph analysis query: {query}.\n","\n","    All the information like programming language and everything would be in lowercase, so generate according to that\n","\n","    Generate the Python Code required to answer the query using the `G_adb` object.\n","\n","    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n","\n","    Only assume that networkx is installed, and other base python dependencies.\n","\n","    import nx_adb afor running on GPU also add this to run on GPU nx.config.backends.arangodb.use_gpu = True and also use the below options\n","\n","    ```Sample code\n","\n","    import networkx as nx\n","    import nx_cugraph as nxcg\n","    import nx_arangodb as nxadb\n","\n","    os.environ[\"NX_CUGRAPH_AUTOCONFIG\"] = \"True\"\n","    nx.config.backends.arangodb.use_gpu = True\n","    nx.config.backend_priority = [\"cugraph\"]\n","\n","    # Convert the ArangoDB graph to a GPU-accelerated graph\n","    G_adb = nxadb.Graph(name=f{userdata.get(\"GRAPH_NAME\")}, db=f{db})\n","\n","    nx.pagerank(G_adb)\n","\n","    ```\n","\n","\n","    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n","\n","    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n","\n","    Make sure that `FINAL_RESULT` stores a short & consice answer. Avoid setting this variable to a long sequence.\n","\n","    Your code:\n","    \"\"\").content\n","\n","    text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n","\n","    logging.info('-'*10)\n","    logging.info(text_to_nx_cleaned)\n","    logging.info('-'*10)\n","\n","\n","    print(text_to_nx_cleaned)\n","\n","    ######################\n","\n","    logging.info(\"\\n2) Executing NetworkX code\")\n","    print(\"2) Executing networkx code\")\n","    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n","    local_vars = {}\n","\n","    try:\n","        exec(text_to_nx_cleaned, global_vars, local_vars)\n","        text_to_nx_final = text_to_nx\n","    except Exception as e:\n","        logging.info(f\"EXEC ERROR: {e}\")\n","        return f\"EXEC ERROR: {e}\"\n","\n","        # TODO: Consider experimenting with a code corrector!\n","        attempt = 1\n","        MAX_ATTEMPTS = 3\n","\n","    logging.debug('-'*10)\n","    FINAL_RESULT = local_vars[\"FINAL_RESULT\"]\n","    logging.debug(f\"FINAL_RESULT: {FINAL_RESULT}\")\n","    logging.debug('-'*10)\n","    print(\"2) Final resukt networkx code\")\n","    ######################\n","\n","    logging.info(\"3) Formulating final answer\")\n","\n","    nx_to_text = llm.invoke(f\"\"\"\n","        I have a NetworkX Graph called `G_adb`. It has the following schema: {arangooGraph.schema}\n","\n","        I have the following graph analysis query: {query}.\n","\n","        I have executed the following python code to help me answer my query:\n","\n","        ---\n","        {text_to_nx_final}\n","        ---\n","\n","        The `FINAL_RESULT` variable is set to the following: {FINAL_RESULT}.\n","\n","        Based on my original Query and FINAL_RESULT, generate a short and concise response to\n","        answer my query.\n","\n","        Your response:\n","    \"\"\").content\n","\n","    return nx_to_text\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H5kQW7XCsLP0"},"outputs":[],"source":["@tool\n","def extractFileStructure(query):\n","    \"\"\"\n","    Extracts the file structure and token information from a GitHub repository.\n","    \"\"\"\n","    logging.info(\"Tool Executing  == GitIngest\")\n","    try:\n","      command = f\"gitingest {query}\"\n","      result = subprocess.run(command, shell=True, check=True, text=True, capture_output=True)\n","      output = result.stdout\n","\n","      parts = output.split(\"Summary:\", 1)\n","      before_summary = parts[0].strip()\n","      summary_part = \"Summary:\" + parts[1] if len(parts) > 1 else \"\"\n","\n","      print(summary_part, 'Part...')\n","\n","      return {\"summary\": summary_part, \"content\": \"./digest.txt\"}\n","    except e:\n","      logging.error(\"Error in Extracting File strcuture\", e)\n","      return \"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JeMYsGTOcrxB"},"outputs":[],"source":["tools = [favourite_fruit, extractFileStructure, humanQueryToAQL, networkxAlgorithms]\n","memory = MemorySaver()\n","def processUserQuery(query:str):\n","    \"\"\"\n","    Processes a user query and returns the response.\n","    \"\"\"\n","\n","    logging.info(\"Processing User Query\", query)\n","    prompt = ChatPromptTemplate.from_messages([\n","        (\"system\", \"You are a helpful bot named octorag, basically a RAG chatbot who helps users understand GitHub repos. If there is a need to execute networkx algorithm, use the result of the tool humanQueryToAQL and create nodes from the result of it and execute networkx algorithm \"),\n","        (\"placeholder\", \"{messages}\"),\n","    ])\n","\n","    model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_retries=2)\n","\n","    model_with_tools = model.bind_tools(tools)\n","    model_with_structured_output = model.with_structured_output(OutputList)\n","\n","\n","    agent = create_react_agent(model, tools, response_format=('if the response contais filepath and text, split the text and files into seperate output',OutputList), checkpointer = memory)\n","    response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]}, config=  {\"configurable\": {\"thread_id\": \"8\"}})\n","\n","    return response[\"structured_response\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176264,"status":"ok","timestamp":1741405270709,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"},"user_tz":480},"id":"gF4MFTpJf7as","outputId":"0e54190c-28c8-4a22-fcd9-f0a44d196ae0"},"outputs":[{"name":"stderr","output_type":"stream","text":["--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 1110, in emit\n","    msg = self.format(record)\n","          ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 953, in format\n","    return fmt.format(record)\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 687, in format\n","    record.message = record.getMessage()\n","                     ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 377, in getMessage\n","    msg = msg % self.args\n","          ~~~~^~~~~~~~~~~\n","TypeError: not all arguments converted during string formatting\n","Call stack:\n","  File \"<frozen runpy>\", line 198, in _run_module_as_main\n","  File \"<frozen runpy>\", line 88, in _run_code\n","  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n","    ColabKernelApp.launch_instance()\n","  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n","    await self.process_one()\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n","    await dispatch(*args)\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n","    await result\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n","    reply_content = await reply_content\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n","    res = shell.run_cell(\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n","    return super().run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-63-5110606ffbf8>\", line 1, in <cell line: 0>\n","    responses = processUserQuery(\"give me information about the repo freecodecamp and generate a page rank algorithm for that\")\n","  File \"<ipython-input-62-3277543b01a7>\", line 8, in processUserQuery\n","    logging.info(\"Processing User Query\", query)\n","Message: 'Processing User Query'\n","Arguments: ('give me information about the repo freecodecamp and generate a page rank algorithm for that',)\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n","INFO:root:Executing Human Query to AQL\n","INFO:root:1) Generating NetworkX code\n","INFO:root:Executing Human Query to AQL\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["AQL Query (1):\u001b[32;1m\u001b[1;3m\n","WITH Github_node, Github_node_to_Github_node\n","FOR repo IN Github_node\n","  FILTER repo.type == \"repository\" AND repo.key == \"repository-freecodecamp\"\n","  RETURN {\n","    repoLink: repo.repoLink,\n","    description: repo.description,\n","    stars: repo.stars,\n","    forks: repo.forks,\n","    size: repo.size\n","  }\n","\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n","INFO:root:----------\n","INFO:root:import os\n","import networkx as nx\n","import nx_cugraph as nxcg\n","import nx_arangodb as nxadb\n","\n","os.environ[\"NX_CUGRAPH_AUTOCONFIG\"] = \"True\"\n","nx.config.backends.arangodb.use_gpu = True\n","nx.config.backend_priority = [\"cugraph\"]\n","\n","# Assuming G_adb is already defined and connected to the ArangoDB instance\n","# Calculate PageRank\n","pagerank_scores = nx.pagerank(G_adb)\n","\n","# Extract the PageRank score for the 'freecodecamp' repository\n","freecodecamp_repo_key = 'repository-freecodecamp'\n","FINAL_RESULT = pagerank_scores.get(freecodecamp_repo_key, \"Repository not found\")\n","INFO:root:----------\n","INFO:root:\n","2) Executing NetworkX code\n"]},{"name":"stdout","output_type":"stream","text":["import os\n","import networkx as nx\n","import nx_cugraph as nxcg\n","import nx_arangodb as nxadb\n","\n","os.environ[\"NX_CUGRAPH_AUTOCONFIG\"] = \"True\"\n","nx.config.backends.arangodb.use_gpu = True\n","nx.config.backend_priority = [\"cugraph\"]\n","\n","# Assuming G_adb is already defined and connected to the ArangoDB instance\n","# Calculate PageRank\n","pagerank_scores = nx.pagerank(G_adb)\n","\n","# Extract the PageRank score for the 'freecodecamp' repository\n","freecodecamp_repo_key = 'repository-freecodecamp'\n","FINAL_RESULT = pagerank_scores.get(freecodecamp_repo_key, \"Repository not found\")\n","2) Executing networkx code\n"]},{"name":"stderr","output_type":"stream","text":["[03:40:47 +0000] [INFO]: Graph 'Github' load took 145.34378266334534s\n","INFO:nx_arangodb:Graph 'Github' load took 145.34378266334534s\n"]},{"name":"stdout","output_type":"stream","text":["AQL Result:\n","\u001b[32;1m\u001b[1;3m[{'repoLink': 'freeCodeCamp/freeCodeCamp', 'description': \"freeCodeCamp.org's open-source codebase and curriculum. Learn to code for free.\", 'stars': 408888, 'forks': 38677, 'size': 483149}]\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["[03:40:51 +0000] [INFO]: NXCG Graph construction took 3.6231637001037598s\n","INFO:nx_arangodb:NXCG Graph construction took 3.6231637001037598s\n","INFO:root:3) Formulating final answer\n"]},{"name":"stdout","output_type":"stream","text":["2) Final resukt networkx code\n"]},{"name":"stderr","output_type":"stream","text":["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["responses=[Outputresponse(type='text', text='The freeCodeCamp repository, available at \"freeCodeCamp/freeCodeCamp,\" is an open-source project that provides a codebase and curriculum for learning to code for free. It has gained significant popularity, boasting 408,888 stars and 38,677 forks. The repository\\'s size is 483,149, indicating a substantial amount of content and resources available for users.'), Outputresponse(type='text', text=\"The PageRank algorithm was executed on the graph, but the 'freecodecamp' repository was not found in the graph's nodes. Please ensure that the repository key 'repository-freecodecamp' exists in the graph and try again.\")]\n"]}],"source":["responses = processUserQuery(\"give me information about the repo freecodecamp and generate a page rank algorithm for that\")\n","\n","print(responses)\n","# for response in responses:\n","#     print(response, 'Response.....')\n","#     print(response[1])\n","#     print(response[1][0].type)\n","    # print(f\"Type: {response.type}, Text: {response.text}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"elapsed":8,"status":"error","timestamp":1741403674629,"user":{"displayName":"Gowtham Kishore “GK”","userId":"10547801038971173877"},"user_tz":480},"id":"jo5cHCp1v0R6","outputId":"506ff18f-523e-4705-a8e2-a1ca67c647c4"},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-31-b3158707970d>, line 1)","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-b3158707970d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Trial Queries\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["#Trial Queries\n","\n","responses = processUserQuery(\"extract the github repository https://github.com/cyclotruc/test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-R9rE_d3v1eq"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1dJJ-AdtRSbhj8eI3mF6u3LLhkx3Ec8g9","authorship_tag":"ABX9TyPfnR0z2tITrRHe/lytB+tO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}